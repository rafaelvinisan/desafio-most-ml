# Sistema Multi-Agente Cient√≠fico (RAG + MCP)

Este projeto implementa um sistema aut√¥nomo de an√°lise cient√≠fica utilizando uma arquitetura **Multi-Agente** orquestrada pelo **CrewAI**. O sistema √© capaz de classificar a √°rea cient√≠fica, extrair dados estruturados e gerar resenhas cr√≠ticas a partir de diversas fontes de entrada (PDF, URL ou Texto).

O diferencial t√©cnico √© o uso do **Model Context Protocol (MCP)** para desacoplar a camada de dados (Vector Store) da camada cognitiva, al√©m de uma estrat√©gia de **RAG H√≠brido** para garantir precis√£o e mitigar alucina√ß√µes.

---

## üèóÔ∏è Arquitetura da Solu√ß√£o

O sistema resolve o desafio de equilibrar a criatividade do LLM com a precis√£o dos dados atrav√©s de dois fluxos distintos (Hybrid Context Strategy):

### 1. Camada de Classifica√ß√£o (RAG / Vector Store)
* **Agente:** `Scientific Taxonomist` (Pesquisador).
* **Mecanismo:** Utiliza a ferramenta `search_articles` (via servidor MCP) para consultar o **Vector Store** (ChromaDB) populado com artigos de refer√™ncia.
* **L√≥gica:** *"Few-Shot Retrieval"*. O agente busca artigos semanticamente similares na base para determinar a qual √°rea (Computa√ß√£o, Medicina, Qu√≠mica) o novo input pertence. Isso evita a cria√ß√£o de categorias n√£o permitidas (ex: "F√≠sica").

### 2. Camada de Extra√ß√£o (Direct Context)
* **Agente:** `Scientific Reviewer` (Analista).
* **Mecanismo:** Recebe a classifica√ß√£o do Pesquisador + o **texto original** do input injetado diretamente no prompt.
* **L√≥gica:** Garante que a extra√ß√£o (JSON) e a resenha sejam fi√©is ao artigo *novo*, e n√£o contaminadas pelos dados dos artigos de refer√™ncia (evitando *Data Leakage*).

---

## üõ†Ô∏è Stack Tecnol√≥gico e Justificativas

Conforme solicitado, abaixo apresento a justificativa para a escolha da stack, priorizando flexibilidade, custo-benef√≠cio e robustez.

| Componente | Escolha | Justificativa T√©cnica |
| :--- | :--- | :--- |
| **Orquestra√ß√£o** | **CrewAI** | Diferente de frameworks puramente conversacionais (AutoGen) ou baseados em grafos complexos (LangGraph), o CrewAI oferece um padr√£o robusto de **Processos Sequenciais**. Isso garante determinismo no fluxo (Pesquisa ‚Üí Extra√ß√£o), essencial para pipelines de produ√ß√£o. |
| **Vector Store** | **ChromaDB** | Banco vetorial nativo Python, open-source e com persist√™ncia em arquivo local. Elimina a necessidade de subir containers Docker pesados (como Weaviate/Milvus) apenas para a avalia√ß√£o, facilitando o "One-Click Run". |
| **Protocolo** | **MCP** | O uso do *Model Context Protocol* padroniza a exposi√ß√£o das ferramentas (`search_articles`, `get_article_content`). Isso desacopla o Agente da implementa√ß√£o do banco: podemos trocar o ChromaDB por Pinecone no futuro sem alterar uma linha do c√≥digo do Agente. |
| **LLM** | **Gemini Flash** | Em testes de carga comparativos, a fam√≠lia **Google Gemini 1.5/2.0 Flash** demonstrou limites de TPM (Tokens Por Minuto) e Janela de Contexto (1M tokens) superiores ao Llama 3 (Groq) no tier gratuito, permitindo processar PDFs inteiros sem cortes ou *Rate Limits* agressivos. |

---

## üöÄ Guia de Instala√ß√£o e Execu√ß√£o

### Pr√©-requisitos
* Python 3.10+
* Gerenciador de pacotes `uv` (Recomendado) ou `pip`.
* Uma chave de API do Google AI Studio.

### 1. Configura√ß√£o de Ambiente
Crie um arquivo `.env` na raiz do projeto:
```env
GEMINI_API_KEY=sua_chave_aqui
```

### 2. Setup Autom√°tico (Via Makefile)
Utilize o make para instalar depend√™ncias e indexar os artigos de refer√™ncia (localizados em `data/pdfs/`).

```bash
# 1. Instala depend√™ncias
make setup

# 2. Processa os PDFs e popula o banco vetorial local (db/)
make index
```

### 3. Subindo o Servidor MCP (HTTP + SSE)

O servidor MCP agora roda como um **servidor HTTP** com **Server-Sent Events (SSE)**.

Em um terminal separado, execute:

```bash
make mcp
```

Isso ir√°:
- **Subir um servidor Uvicorn** apontando para `src/mcp_server.py`.
- Expor o endpoint SSE em `http://localhost:8000/sse`.
- Expor o endpoint de mensagens em `http://localhost:8000/messages` (usado internamente pelo MCP).

Mantenha este terminal **aberto**, pois o agente/cliente se conecta a esse servidor.

## üìö Como Usar (CLI)

O sistema possui uma CLI robusta em `src/agent.py` capaz de processar URLs, Arquivos PDF locais ou Texto Bruto.
Internamente, o agente se conecta ao servidor MCP via SSE usando o endpoint:

```text
MCP_SERVER_URL = "http://localhost:8000/sse"
```

Por isso, **certifique-se de que o comando `make mcp` est√° rodando em outro terminal** antes de executar o agente.

### 1. Execu√ß√£o via Makefile (Recomendado)

**Sintaxe (via `make agent`):**

```bash
make mcp                               # em um terminal separado
make agent SOURCE="FONTE" NAME="nome"  # em outro terminal
```

Onde:
- **`SOURCE`**: caminho de arquivo PDF, URL ou texto bruto.
- **`NAME`**: nome-base para os arquivos de sa√≠da em `out/` (sem extens√£o).

#### Exemplos com `make agent`

- **URL (Transformers no ArXiv)**:

```bash
make mcp
make agent SOURCE="https://arxiv.org/abs/1706.03762" NAME="analise_transformers"
```

- **PDF Local**:

```bash
make mcp
make agent SOURCE="samples/input_article_1.pdf" NAME="analise_local"
```

- **Texto Bruto**:

```bash
make mcp
make agent SOURCE="We propose a new network architecture..." NAME="teste_texto"
```

### 2. Execu√ß√£o direta via Python (Alternativa)

Voc√™ tamb√©m pode chamar diretamente o script `src/agent.py`:

```bash
make mcp                              # em um terminal separado
uv run python src/agent.py [FONTE] --name [NOME_DO_OUTPUT]
```

Exemplos equivalentes:

```bash
# URL
make mcp
uv run python src/agent.py "https://arxiv.org/abs/1706.03762" --name analise_transformers

# PDF Local
make mcp
uv run python src/agent.py samples/input_article_1.pdf --name analise_local

# Texto Bruto
make mcp
uv run python src/agent.py "We propose a new network architecture..." --name teste_texto
```

## üì¶ Sa√≠da e Resultados

Todos os resultados s√£o salvos automaticamente na pasta `out/`. Para cada execu√ß√£o:

* **`{nome}.json`**: Dados estruturados.
  * Mant√©m o idioma original na extra√ß√£o (conforme edital).
  * Inclui a chave obrigat√≥ria com typo: `what problem does the artcle propose to solve?`.
* **`review_{nome}.md`**: Resenha cr√≠tica formatada em Portugu√™s.

## üõ°Ô∏è Robustez e Hardening

O projeto implementa camadas de defesa ("Hardening") validadas por testes:

* **Valida√ß√£o de Input**: O sistema rejeita textos muito curtos ou PDFs corrompidos/vazios antes de chamar a API, economizando custos.
* **Rate Limiting Manual**: Implementa√ß√£o de `sleep` estrat√©gico e `max_rpm` no CrewAI para respeitar as cotas estritas do tier gratuito do Gemini.
* **Parser JSON Resiliente**: Utiliza Regex para extrair e corrigir JSONs mal formatados pelo LLM (ex: v√≠rgulas extras), garantindo que o pipeline n√£o quebre por erros de sintaxe.
* **Tratamento de Erros**: Captura falhas de rede, timeouts do servidor MCP e erros de API com mensagens claras ao usu√°rio.

## ‚úÖ Testes Automatizados

O projeto inclui uma su√≠te de testes (`pytest`) cobrindo l√≥gica de extra√ß√£o, limpeza de input e cen√°rios de falha.

### 1. Testes gerais

```bash
make test
# Ou: uv run pytest tests/ -v
```

### 2. Cen√°rios espec√≠ficos do edital (atalhos via Makefile)

Cada cen√°rio j√° est√° mapeado em um alvo `make`:

- **`make test1`** ‚Äì PDF local de exemplo:

```bash
make mcp
make test1
```

- **`make test2`** ‚Äì URL externa (ArXiv):

```bash
make mcp
make test2
```

- **`make test3`** ‚Äì Edge case (F√≠sica Te√≥rica / Schrodinger):

```bash
make mcp
make test3
```

## üìÇ Estrutura do Projeto

```
.
‚îú‚îÄ‚îÄ data/pdfs/         # Artigos de refer√™ncia (Base de Conhecimento)
‚îú‚îÄ‚îÄ db/                # Banco vetorial (ChromaDB - Gerado no setup)
‚îú‚îÄ‚îÄ out/               # Artefatos gerados (JSON e Markdown)
‚îú‚îÄ‚îÄ samples/           # Arquivos de exemplo para testes
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ agent.py       # Orquestra√ß√£o dos Agentes e CLI
‚îÇ   ‚îú‚îÄ‚îÄ ingest.py      # Pipeline de Ingest√£o e Indexa√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ mcp_server.py  # Servidor MCP (Ferramentas de Busca)
‚îÇ   ‚îî‚îÄ‚îÄ utils.py       # Parsers, Scrapers e Validadores (Test√°veis)
‚îú‚îÄ‚îÄ tests/             # Testes Unit√°rios e de Hardening
‚îú‚îÄ‚îÄ Makefile           # Automa√ß√£o de comandos
‚îî‚îÄ‚îÄ pyproject.toml     # Depend√™ncias
```
