# Sistema Multi-Agente CientÃ­fico (RAG + MCP)

Este projeto implementa um sistema autÃ´nomo de anÃ¡lise cientÃ­fica utilizando uma arquitetura **Multi-Agente** orquestrada pelo **CrewAI**. O sistema Ã© capaz de classificar a Ã¡rea cientÃ­fica, extrair dados estruturados e gerar resenhas crÃ­ticas a partir de diversas fontes de entrada (PDF, URL ou Texto).

O diferencial tÃ©cnico Ã© o uso do **Model Context Protocol (MCP)** para desacoplar a camada de dados (Vector Store) da camada cognitiva, alÃ©m de uma estratÃ©gia de **RAG HÃ­brido** para garantir precisÃ£o e mitigar alucinaÃ§Ãµes.

---

## ğŸ—ï¸ Arquitetura da SoluÃ§Ã£o

O sistema resolve o desafio de equilibrar a criatividade do LLM com a precisÃ£o dos dados atravÃ©s de dois fluxos distintos (Hybrid Context Strategy):

### 1. Camada de ClassificaÃ§Ã£o (RAG / Vector Store)
* **Agente:** `Scientific Taxonomist` (Pesquisador).
* **Mecanismo:** Utiliza a ferramenta `search_articles` (via servidor MCP) para consultar o **Vector Store** (ChromaDB) populado com artigos de referÃªncia.
* **LÃ³gica:** *"Few-Shot Retrieval"*. O agente busca artigos semanticamente similares na base para determinar a qual Ã¡rea (ComputaÃ§Ã£o, Medicina, QuÃ­mica) o novo input pertence. Isso evita a criaÃ§Ã£o de categorias nÃ£o permitidas (ex: "FÃ­sica").

### 2. Camada de ExtraÃ§Ã£o (Direct Context)
* **Agente:** `Scientific Reviewer` (Analista).
* **Mecanismo:** Recebe a classificaÃ§Ã£o do Pesquisador + o **texto original** do input injetado diretamente no prompt.
* **LÃ³gica:** Garante que a extraÃ§Ã£o (JSON) e a resenha sejam fiÃ©is ao artigo *novo*, e nÃ£o contaminadas pelos dados dos artigos de referÃªncia (evitando *Data Leakage*).

---

## ğŸ› ï¸ Stack TecnolÃ³gico e Justificativas

Conforme solicitado, abaixo apresento a justificativa para a escolha da stack, priorizando flexibilidade, custo-benefÃ­cio e robustez.

| Componente | Escolha | Justificativa TÃ©cnica |
| :--- | :--- | :--- |
| **OrquestraÃ§Ã£o** | **CrewAI** | Diferente de frameworks puramente conversacionais (AutoGen) ou baseados em grafos complexos (LangGraph), o CrewAI oferece um padrÃ£o robusto de **Processos Sequenciais**. Isso garante determinismo no fluxo (Pesquisa â†’ ExtraÃ§Ã£o), essencial para pipelines de produÃ§Ã£o. |
| **Vector Store** | **ChromaDB** | Banco vetorial nativo Python, open-source e com persistÃªncia em arquivo local. Elimina a necessidade de subir containers Docker pesados (como Weaviate/Milvus) apenas para a avaliaÃ§Ã£o, facilitando o "One-Click Run". |
| **Protocolo** | **MCP** | O uso do *Model Context Protocol* padroniza a exposiÃ§Ã£o das ferramentas (`search_articles`, `get_article_content`). Isso desacopla o Agente da implementaÃ§Ã£o do banco: podemos trocar o ChromaDB por Pinecone no futuro sem alterar uma linha do cÃ³digo do Agente. |
| **LLM** | **Gemini Flash** | Em testes de carga comparativos, a famÃ­lia **Google Gemini 1.5/2.0 Flash** demonstrou limites de TPM (Tokens Por Minuto) e Janela de Contexto (1M tokens) superiores ao Llama 3 (Groq) no tier gratuito, permitindo processar PDFs inteiros sem cortes ou *Rate Limits* agressivos. |

---

## ğŸš€ Guia de InstalaÃ§Ã£o e ExecuÃ§Ã£o

### PrÃ©-requisitos
* Python 3.10+
* Gerenciador de pacotes `uv` (Recomendado) ou `pip`.
* Uma chave de API do Google AI Studio.

### 1. ConfiguraÃ§Ã£o de Ambiente
Crie um arquivo `.env` na raiz do projeto:
```env
GEMINI_API_KEY=sua_chave_aqui
```

### 2. Setup AutomÃ¡tico (Via Makefile)
Utilize o make para instalar dependÃªncias e indexar os artigos de referÃªncia (localizados em `data/pdfs/`).

```bash
# 1. Instala dependÃªncias
make setup

# 2. Processa os PDFs e popula o banco vetorial local (db/)
make index
```

## ğŸ“š Como Usar (CLI)

O sistema possui uma CLI robusta em `src/agent.py` capaz de processar URLs, Arquivos PDF locais ou Texto Bruto.

**Sintaxe:**
```bash
python src/agent.py [FONTE] --name [NOME_DO_OUTPUT]
```

### CenÃ¡rio 1: Analisando uma URL (Recomendado)
O sistema baixa o HTML/PDF, limpa menus/scripts e processa o conteÃºdo.

```bash
# Exemplo: Artigo sobre Transformers no ArXiv
python src/agent.py "https://arxiv.org/abs/1706.03762" --name analise_transformers
```

### CenÃ¡rio 2: Analisando um PDF Local
Utiliza `pypdf` com validaÃ§Ã£o de OCR.

```bash
python src/agent.py samples/meu_artigo.pdf --name analise_local
```

### CenÃ¡rio 3: Analisando Texto Bruto
Ideal para testes rÃ¡pidos.

```bash
python src/agent.py "We propose a new network architecture..." --name teste_texto
```

## ğŸ“¦ SaÃ­da e Resultados

Todos os resultados sÃ£o salvos automaticamente na pasta `out/`. Para cada execuÃ§Ã£o:

* **`{nome}.json`**: Dados estruturados.
  * MantÃ©m o idioma original na extraÃ§Ã£o (conforme edital).
  * Inclui a chave obrigatÃ³ria com typo: `what problem does the artcle propose to solve?`.
* **`review_{nome}.md`**: Resenha crÃ­tica formatada em PortuguÃªs.

## ğŸ›¡ï¸ Robustez e Hardening

O projeto implementa camadas de defesa ("Hardening") validadas por testes:

* **ValidaÃ§Ã£o de Input**: O sistema rejeita textos muito curtos ou PDFs corrompidos/vazios antes de chamar a API, economizando custos.
* **Rate Limiting Manual**: ImplementaÃ§Ã£o de `sleep` estratÃ©gico e `max_rpm` no CrewAI para respeitar as cotas estritas do tier gratuito do Gemini.
* **Parser JSON Resiliente**: Utiliza Regex para extrair e corrigir JSONs mal formatados pelo LLM (ex: vÃ­rgulas extras), garantindo que o pipeline nÃ£o quebre por erros de sintaxe.
* **Tratamento de Erros**: Captura falhas de rede, timeouts do servidor MCP e erros de API com mensagens claras ao usuÃ¡rio.

## âœ… Testes Automatizados

O projeto inclui uma suÃ­te de testes (`pytest`) cobrindo lÃ³gica de extraÃ§Ã£o, limpeza de input e cenÃ¡rios de falha.

```bash
make test
# Ou: uv run pytest tests/ -v
```

## ğŸ“‚ Estrutura do Projeto

```
.
â”œâ”€â”€ data/pdfs/         # Artigos de referÃªncia (Base de Conhecimento)
â”œâ”€â”€ db/                # Banco vetorial (ChromaDB - Gerado no setup)
â”œâ”€â”€ out/               # Artefatos gerados (JSON e Markdown)
â”œâ”€â”€ samples/           # Arquivos de exemplo para testes
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agent.py       # OrquestraÃ§Ã£o dos Agentes e CLI
â”‚   â”œâ”€â”€ ingest.py      # Pipeline de IngestÃ£o e IndexaÃ§Ã£o
â”‚   â”œâ”€â”€ mcp_server.py  # Servidor MCP (Ferramentas de Busca)
â”‚   â””â”€â”€ utils.py       # Parsers, Scrapers e Validadores (TestÃ¡veis)
â”œâ”€â”€ tests/             # Testes UnitÃ¡rios e de Hardening
â”œâ”€â”€ Makefile           # AutomaÃ§Ã£o de comandos
â””â”€â”€ pyproject.toml     # DependÃªncias
```
